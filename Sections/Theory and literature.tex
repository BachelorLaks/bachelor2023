\section{Theory and literature}

Relevant theory will be: 
We envision using economic theories such as market equilibrium, Pareto efficiency and consumer choice theory. 
Statistical theory, such as the presumptions for regression to evaluate whether our data sources meet the requirements, and our model is robust. 
Neural networks, especially LSTM compared to other predictive models 

\subsection{Tensor flow}

\subsection{ARIMA --- SARIMAX}

The ARIMA-model is one of the more popular and useful approaches to time series forecasting. The name is an acronym that stands for AutoRegressive Integrated Moving Average and the model utilizes these in order to predict future values solely on earlier values, it is therefore an univariate model. The SARIMAX-model is an extension of the ARIMA-model that also takes external factors and seasonality into account in order to better predict future values. SARIMAX can therefore be a multivariate model. \parencite{hyndman_athanasopoulos_2021}

\subsubsection{Auto Regressive (AR)}
The first part of the ARIMA acronym is the Auto Regressive part. Auto comes from the greek word autos and mean self, in this context it means that the model is regressing on itself. This part of the model can be written as follows:
\begin{equation}
y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + \cdots + \phi_{p}y_{t-p} + \varepsilon_{t}
\end{equation}

Where c is a constant, $p$ is the number of lag observations or autoregressive terms, $\phi$ are the AR coefficients and $\varepsilon_{t}$ is the error term. $y_{t}$ is the data on which the AR-model is applied on. (\cite{oracle_ARIMA}) This model is a ``pure'' AR-model and relies therefore solely on its own lags. If $p$ is set to 1, the model looks at the previous value and tries to predict the next value. If $p$ is set to 2, the model looks at the previous two values and tries to predict the next value, and so on. (\cite{artley_2022})


\subsubsection{Integrated (I)}
The second part of the ARIMA acronym is the Integrated part. This part of the model is used to make the time series stationary. In the ARIMA-equation it is represented by the letter $d$ and is the number of differencing required to make the time series stationary. Usually the optimal amount of differencing is the least amount needed to make the data fluctuate around a well defined mean. (\cite{nau_2019}) 

\subsubsection{Moving Average (MA)}
The third and last part of the ARIMA acronym is the Moving Average part. This incorporates the dependency of an observation on the residual errors from a moving average model applied to lagged observations. \parencite{hayes_2019} This part of the model can be written as follows:
\begin{equation}
\hat{y} = c + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \cdots + \theta_q\epsilon_{t-q}
\end{equation}

Where c is a constant, $q$ is the order of the moving average, i.e the number of lagged forecast errors. $\theta$ are the MA coefficients and $\varepsilon_{t}$ is the error term. For example, if $q$ is 1, the output relies solely on the errors from the previous time step. If $q$ is 2, the output relies on the errors from the previous two time steps. (\cite{hyndman_athanasopoulos_2021}) 

Combining these three parts of the ARIMA-model, we get the following general forecasting equation:
\begin{equation}
\hat{y}_t = c + \phi_1y_{t-1} + \phi_2y_{t-2} + \cdots + \phi_py_{t-p} + \theta_1\epsilon_{t-1} + \theta_2\epsilon_{t-2} + \cdots + \theta_q\epsilon_{t-q} + \epsilon_t
\end{equation}

\subsubsection{Seasonality}


\subsubsection{Exogenous variables}

\subsection{Exploratory analysis}
\textbf{Exploratory data analysis (EDA)} is a method used to analyse datasets and summarize the main characteristics. It helps determine how best to manipulate datasources to get the answers needed. This makes it easier to discover patterns, anomalies, test hypotheses or checking assumptions (https://www.youtube.com/watch?v=QiqZliDXCCg).

\subsection{Regression}
Regression analysis is a reliable method of identifying which variables have impact on a topic of interest. Regression analysis consists of two types of variables; dependent and independent. The dependent variable is the main variable or factor that aasdasd is trying to predict or understand. The independent variables are the factors that dasdasd hypothesize to have an impact on the chosen dependent variable. 

Linear regression models often use a "least-squares approach" to determine a line of best fit (regression line) to a given dataset. This line is the yellow line in the figure below. A square is the squared distance between a datapoint and the regression line. These values needs to be squared in order to not counteract each other.   

BILDE

When the process above has been completed a regression model is constructed. The genereal form of a \textbf{multiple linear regression model} is:  

- Regression, https://www.alchemer.com/resources/blog/regression-analysis/\\ 

https://www.investopedia.com/terms/r/regression.asp

\subsection{Neural networks}
\subsubsection{Recurrent Neural Network}
\subsubsection{Long Short-Term Memory}