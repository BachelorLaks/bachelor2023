{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages for tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, LSTM, LeakyReLU, BatchNormalization, Conv1D, MaxPooling1D, Activation\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x42f756f50>"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_set = pd.read_csv('var_set.csv', parse_dates=[0],index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalmonPrice</th>\n",
       "      <th>CodPrice</th>\n",
       "      <th>HalibutPrice</th>\n",
       "      <th>CPI</th>\n",
       "      <th>TWI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-04-07</th>\n",
       "      <td>39.63</td>\n",
       "      <td>10.754267</td>\n",
       "      <td>47.577612</td>\n",
       "      <td>95.55</td>\n",
       "      <td>92.1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-14</th>\n",
       "      <td>41.89</td>\n",
       "      <td>10.800751</td>\n",
       "      <td>47.924958</td>\n",
       "      <td>95.70</td>\n",
       "      <td>92.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-21</th>\n",
       "      <td>43.07</td>\n",
       "      <td>10.774089</td>\n",
       "      <td>47.092639</td>\n",
       "      <td>95.85</td>\n",
       "      <td>92.7980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-04-28</th>\n",
       "      <td>42.70</td>\n",
       "      <td>10.569605</td>\n",
       "      <td>47.193296</td>\n",
       "      <td>96.00</td>\n",
       "      <td>93.8080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-05</th>\n",
       "      <td>41.81</td>\n",
       "      <td>10.605343</td>\n",
       "      <td>48.987917</td>\n",
       "      <td>96.02</td>\n",
       "      <td>93.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-20</th>\n",
       "      <td>82.49</td>\n",
       "      <td>39.417280</td>\n",
       "      <td>76.897925</td>\n",
       "      <td>128.50</td>\n",
       "      <td>122.2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-27</th>\n",
       "      <td>79.03</td>\n",
       "      <td>39.071706</td>\n",
       "      <td>73.642666</td>\n",
       "      <td>128.40</td>\n",
       "      <td>122.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-04</th>\n",
       "      <td>78.05</td>\n",
       "      <td>42.701713</td>\n",
       "      <td>73.193629</td>\n",
       "      <td>128.70</td>\n",
       "      <td>120.8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-11</th>\n",
       "      <td>75.83</td>\n",
       "      <td>43.652968</td>\n",
       "      <td>74.156841</td>\n",
       "      <td>129.00</td>\n",
       "      <td>122.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-18</th>\n",
       "      <td>86.64</td>\n",
       "      <td>49.076318</td>\n",
       "      <td>79.182888</td>\n",
       "      <td>129.30</td>\n",
       "      <td>122.3580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>507 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SalmonPrice   CodPrice  HalibutPrice     CPI       TWI\n",
       "2013-04-07        39.63  10.754267     47.577612   95.55   92.1500\n",
       "2013-04-14        41.89  10.800751     47.924958   95.70   92.1920\n",
       "2013-04-21        43.07  10.774089     47.092639   95.85   92.7980\n",
       "2013-04-28        42.70  10.569605     47.193296   96.00   93.8080\n",
       "2013-05-05        41.81  10.605343     48.987917   96.02   93.3125\n",
       "...                 ...        ...           ...     ...       ...\n",
       "2022-11-20        82.49  39.417280     76.897925  128.50  122.2180\n",
       "2022-11-27        79.03  39.071706     73.642666  128.40  122.0320\n",
       "2022-12-04        78.05  42.701713     73.193629  128.70  120.8780\n",
       "2022-12-11        75.83  43.652968     74.156841  129.00  122.7060\n",
       "2022-12-18        86.64  49.076318     79.182888  129.30  122.3580\n",
       "\n",
       "[507 rows x 5 columns]"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = var_set.drop(columns=[\"SalmonPrice\"], axis = 1)\n",
    "y = var_set[\"SalmonPrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_uni = var_set[\"SalmonPrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_uni_train,y_uni_test = train_test_split(x_uni, test_size = 50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457,)"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions\n",
    "# test_predictions = []\n",
    "\n",
    "# first_eval_batch = x_minmax_train[-52:]\n",
    "# current_batch = first_eval_batch.reshape((1, 52, 1))\n",
    "\n",
    "# for i in range(len(y_minmax_test)):\n",
    "#     current_pred = model.predict(current_batch)[0]\n",
    "#     test_predictions.append(current_pred)\n",
    "#     current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n",
    "\n",
    "# true_predictions = scaler.inverse_transform(test_predictions)\n",
    "\n",
    "# # Plot the predictions\n",
    "# test_predictions = pd.Series(true_predictions.reshape(50,))\n",
    "# y_uni_test = pd.Series(y_uni_test.reshape(50,))\n",
    "# plt.plot(y_uni_test, label='Test Data')\n",
    "# plt.plot(test_predictions, label='Predictions')\n",
    "# plt.legend()\n",
    "\n",
    "# # Evaluate the model\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from math import sqrt\n",
    "\n",
    "# rmse = sqrt(mean_squared_error(y_uni_test, test_predictions))\n",
    "# print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale x and y multivariate\n",
    "scaler_x = MinMaxScaler()\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n",
    "# Scale y\n",
    "scaler_y = MinMaxScaler()\n",
    "y_train = scaler_y.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test = scaler_y.transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 4)"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(457, 1)"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1\n",
      "Lookback -- input: 1\n",
      "Optimizer: adam\n",
      "Epochs: 10\n",
      "Univariate\n",
      "Run: 1\n",
      "model_name1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 17:24:29.510112: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.82496224]]]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 17:24:49.687788: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test RMSE: 32.274\n",
      "Batch size: 1\n",
      "Lookback -- input: 1\n",
      "Optimizer: adam\n",
      "Epochs: 10\n",
      "Multivariate\n",
      "Run: 2\n",
      "model_name2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/_0zst1c12b9_m_438bw49zw40000gn/T/ipykernel_74781/3651584601.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  rmse_df = rmse_df.append({'Model Name' : model_name_string, 'Run': run, 'Model alternative':m1+1, 'Batch Size': i, 'Epochs': j, 'Optimizer' : opt, 'Time steps':n, 'Uni/Multi' :uni_name, 'RMSE': rmse}, ignore_index=True)\n",
      "2023-04-25 17:24:51.459931: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.82496224]]]\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 17:25:09.119682: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "Test RMSE: 31.126\n",
      "Batch size: 1\n",
      "Lookback -- input: 1\n",
      "Optimizer: adam\n",
      "Epochs: 40\n",
      "Univariate\n",
      "Run: 3\n",
      "model_name3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/_0zst1c12b9_m_438bw49zw40000gn/T/ipykernel_74781/3651584601.py:78: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  rmse_df = rmse_df.append({'Model Name' : model_name_string, 'Run': run, 'Model alternative':m1+1, 'Batch Size': i, 'Epochs': j, 'Optimizer' : opt, 'Time steps':n, 'Uni/Multi' :uni_name, 'RMSE': rmse}, ignore_index=True)\n",
      "2023-04-25 17:25:10.857091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[795], line 62\u001b[0m\n\u001b[1;32m     60\u001b[0m model_name\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m history \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhistory\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(run)\n\u001b[0;32m---> 62\u001b[0m history \u001b[39m=\u001b[39m model_name\u001b[39m.\u001b[39;49mfit(generated_batches,epochs\u001b[39m=\u001b[39;49mj,verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m     63\u001b[0m \u001b[39m#print(model_name.summary())\u001b[39;00m\n\u001b[1;32m     64\u001b[0m model_name_test \u001b[39m=\u001b[39m model_name\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bachelor2023/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bachelor2023/lib/python3.10/site-packages/keras/engine/training.py:1401\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   1400\u001b[0m   data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_load_initial_step_from_ckpt()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m   \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1402\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m         epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m         step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m         _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m       callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bachelor2023/lib/python3.10/site-packages/keras/engine/data_adapter.py:1248\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m   \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1248\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1249\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1250\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m   1253\u001b[0m     original_spe)\n\u001b[1;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bachelor2023/lib/python3.10/site-packages/tensorflow/python/ops/resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bachelor2023/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1159\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \n\u001b[1;32m   1138\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/bachelor2023/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1125\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1124\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1126\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.optimizers.legacy import Adam\n",
    "batch_size = [1, 2, 13, 26, 52, 104] #i\n",
    "\n",
    "epochs = [10, 40, 100]\n",
    "#epochs = [1, 2, 3]\n",
    "\n",
    "rmse_list = []\n",
    "\n",
    "n_input = [1, 4, 52, 104] #n\n",
    "#n_input = [24, 52] #n\n",
    "\n",
    "run = 0\n",
    "b = 0\n",
    "e = 0\n",
    "\n",
    "m1 = 0\n",
    "m2 = 0\n",
    "\n",
    "uni_multi = [X_train, y_train]\n",
    "\n",
    "optimuzer = ['adam', 'nadam']\n",
    "\n",
    "rmse_df = pd.DataFrame(columns=['Run', 'Batch Size', 'Epochs'])\n",
    "for i in batch_size:\n",
    "    for opt in optimuzer:\n",
    "        for n in n_input:\n",
    "            b = b + 1\n",
    "            for j in epochs:\n",
    "                for m1 in range(1):\n",
    "                    for vari in uni_multi:\n",
    "                        e = e + 1\n",
    "                        print('Batch size: '+str(i))\n",
    "                        print('Lookback -- input: '+str(n))\n",
    "                        print('Optimizer: '+str(opt))\n",
    "                        print('Epochs: '+str(j))\n",
    "                        \n",
    "                        if run % 2 == 0:\n",
    "                            uni_name = 'Univariate'\n",
    "                        else:\n",
    "                            uni_name = 'Multivariate'\n",
    "                        print(uni_name)\n",
    "                        run = run + 1\n",
    "                        print('Run: '+str(run))\n",
    "                        generated_batches = TimeseriesGenerator(vari, y_train, length=n, batch_size=1)\n",
    "                        model_name_string = 'Model'+ ' ' + str(run)\n",
    "                        model_name = 'model_name' + str(run)\n",
    "                        model_name_test = 'model_name' + str(run)\n",
    "                        print(model_name)\n",
    "                        model_name = Sequential()\n",
    "                        model_name.add(Flatten(input_shape=(n,1)))\n",
    "                        #model_name.add(Dense(1024, activation='relu', name=\"hidden_layer_1\"))\n",
    "                        if m1 == 1:\n",
    "                            model_name.add(Dense(128, activation='relu'))\n",
    "                            model_name.add(Dropout(0.1))\n",
    "                            model_name.add(Dense(64, activation='relu'))\n",
    "                            model_name.add(Dropout(0.1))\n",
    "                        #m1 = m1 + 1\n",
    "                        model_name.add(Dense(32, activation='relu'))\n",
    "                        model_name.add(Dense(1))\n",
    "                        model_name.compile(optimizer=opt, loss='mse')\n",
    "                        history = 'history'+str(run)\n",
    "                        history = model_name.fit(generated_batches,epochs=j,verbose=0, batch_size=i)\n",
    "                        #print(model_name.summary())\n",
    "                        model_name_test = model_name\n",
    "                        test_predictions = []\n",
    "                        first_eval_batch = y_train[-n:]\n",
    "                        current_batch = first_eval_batch.reshape((1, n, 1))\n",
    "                        print(current_batch)\n",
    "                        for k in range(len(y_test)):\n",
    "                            current_pred = model_name.predict(current_batch)[0]\n",
    "                            test_predictions.append(current_pred)\n",
    "                            current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)\n",
    "                        true_predictions = scaler_y.inverse_transform(test_predictions)\n",
    "                        #print(test_predictions)\n",
    "                        \n",
    "                        y_test_inverse = scaler_y.inverse_transform(y_test)\n",
    "                        rmse = sqrt(mean_squared_error(y_test_inverse, true_predictions))\n",
    "                        rmse_df = rmse_df.append({'Model Name' : model_name_string, 'Run': run, 'Model alternative':m1+1, 'Batch Size': i, 'Epochs': j, 'Optimizer' : opt, 'Time steps':n, 'Uni/Multi' :uni_name, 'RMSE': rmse}, ignore_index=True)\n",
    "                        rmse_list.append(rmse)\n",
    "                        print('Test RMSE: %.3f' % rmse)\n",
    "                        #mse = mean_squared_error(y_test_inverse, true_predictions)\n",
    "                        #print('Test MSE: %.3f' % mse)\n",
    "                        plot_predictions = pd.Series(true_predictions.reshape(50,))\n",
    "                        y_test_inverse = pd.Series(y_test_inverse.reshape(50,))\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        plt.plot(history.history['loss'], label='Loss(MSE)')\n",
    "                        plt.legend()\n",
    "                        plt.savefig('Figures/Neural networks/ForLoop_Tensor/plotLoss_'+str(run)+'.png')\n",
    "\n",
    "                        plt.figure(figsize=(18,10))\n",
    "                        plt.plot(plot_predictions, label='Forecast')\n",
    "                        plt.plot(y_test_inverse, label='Actual')\n",
    "                        plt.legend()\n",
    "                        plt.savefig('Figures/Neural networks/ForLoop_Tensor/plotModel_'+str(run)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = scaler_y.inverse_transform(y_test)\n",
    "# plot_predictions = pd.Series(true_predictions.reshape(50,))\n",
    "# y_test = pd.Series(y_test.reshape(50,))\n",
    "# plt.plot(y_test, label='Test Data')\n",
    "# plt.plot(plot_predictions, label='Predictions')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32.27404859161346, 31.126496687922444]"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70.45275782],\n",
       "       [69.40175352],\n",
       "       [68.40413469],\n",
       "       [67.45718976],\n",
       "       [66.55833973],\n",
       "       [65.7051445 ],\n",
       "       [64.89529024],\n",
       "       [64.12657044],\n",
       "       [63.39689224],\n",
       "       [62.70427957],\n",
       "       [62.04684789],\n",
       "       [61.42281054],\n",
       "       [60.83046923],\n",
       "       [60.26821722],\n",
       "       [59.73452038],\n",
       "       [59.22793295],\n",
       "       [58.74706916],\n",
       "       [58.29050535],\n",
       "       [57.85701359],\n",
       "       [57.44543221],\n",
       "       [57.05465324],\n",
       "       [56.68362235],\n",
       "       [56.33134203],\n",
       "       [55.99686528],\n",
       "       [55.67929246],\n",
       "       [55.37777126],\n",
       "       [55.09148727],\n",
       "       [54.81966711],\n",
       "       [54.5615879 ],\n",
       "       [54.31654727],\n",
       "       [54.08389182],\n",
       "       [53.86299492],\n",
       "       [53.65325999],\n",
       "       [53.45412512],\n",
       "       [53.2650537 ],\n",
       "       [53.08553906],\n",
       "       [52.91509668],\n",
       "       [52.7532704 ],\n",
       "       [52.59961988],\n",
       "       [52.45373475],\n",
       "       [52.31522357],\n",
       "       [52.18371072],\n",
       "       [52.0588458 ],\n",
       "       [51.94029263],\n",
       "       [51.82772922],\n",
       "       [51.72085253],\n",
       "       [51.61937848],\n",
       "       [51.523034  ],\n",
       "       [51.43155709],\n",
       "       [51.34470469]])"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      71.52\n",
       "1      70.81\n",
       "2      73.48\n",
       "3      80.66\n",
       "4      92.82\n",
       "5      91.41\n",
       "6      85.35\n",
       "7      82.96\n",
       "8      80.61\n",
       "9      86.38\n",
       "10     88.64\n",
       "11    102.78\n",
       "12    109.91\n",
       "13    115.17\n",
       "14    125.87\n",
       "15    122.75\n",
       "16    104.69\n",
       "17     99.34\n",
       "18    102.89\n",
       "19    101.13\n",
       "20    107.09\n",
       "21    106.90\n",
       "22    105.15\n",
       "23     98.30\n",
       "24     95.84\n",
       "25     92.30\n",
       "26     79.14\n",
       "27     70.89\n",
       "28     72.56\n",
       "29     71.69\n",
       "30     65.78\n",
       "31     59.56\n",
       "32     57.15\n",
       "33     60.74\n",
       "34     62.40\n",
       "35     62.88\n",
       "36     63.23\n",
       "37     68.21\n",
       "38     71.80\n",
       "39     70.86\n",
       "40     69.96\n",
       "41     67.62\n",
       "42     66.20\n",
       "43     70.70\n",
       "44     80.64\n",
       "45     82.49\n",
       "46     79.03\n",
       "47     78.05\n",
       "48     75.83\n",
       "49     86.64\n",
       "dtype: float64"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df['Epochs'] = rmse_df['Epochs'].astype(int)\n",
    "rmse_df['Batch Size'] = rmse_df['Batch Size'].astype(int)\n",
    "rmse_df['Run'] = rmse_df['Run'].astype(int)\n",
    "rmse_df['Model alternative'] = rmse_df['Model alternative'].astype(int)\n",
    "rmse_df['Time steps'] = rmse_df['Time steps'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df.insert(8, 'RMSE', rmse_df.pop('RMSE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Model alternative</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Time steps</th>\n",
       "      <th>Uni/Multi</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Model 1</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>32.274049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Model 2</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>1</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>31.126497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Run  Batch Size  Epochs Model Name  Model alternative Optimizer  \\\n",
       "0    1           1      10    Model 1                  1      adam   \n",
       "1    2           1      10    Model 2                  1      adam   \n",
       "\n",
       "   Time steps     Uni/Multi       RMSE  \n",
       "0           1    Univariate  32.274049  \n",
       "1           1  Multivariate  31.126497  "
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df.style.to_latex(\"Figures/Neural networks/RMSE_Tensorflow.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df.to_csv('Figures/Neural networks/RMSE_Tensorflow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df.sort_values(by=['RMSE']).head(20).style.to_latex(\"Figures/Neural networks/RMSE_Tensorflow_top20.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = []\n",
    "\n",
    "# batch = X_train[-n_input:].reshape((1, n_input, 1))\n",
    "\n",
    "# for i in range(n_input):   \n",
    "#     pred_list.append(model_name.predict(batch)[0]) \n",
    "#     batch = np.append(batch[:,1:,:],[[pred_list[i]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = scaler_x.inverse_transform(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(pred_list, label='Predictions')\n",
    "# plt.plot(scaler_x.inverse_transform(X_test), label='True Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.tseries.offsets import DateOffset\n",
    "# df = pd.DataFrame()\n",
    "# add_dates = [df.index[-1] + DateOffset(months=x) for x in range(0,13) ]\n",
    "# future_dates = pd.DataFrame(index=add_dates[1:],columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_df.sort_values(by=['RMSE'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with RMSE values when length of values does not match length of index\n",
    "# rmse_df = pd.DataFrame(rmse_list, columns = ['RMSE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataframe with RMSE values\n",
    "# rmse_df = pd.DataFrame(rmse_list, columns = ['RMSE'])\n",
    "# rmse_df['Batch Size'] = batch_size\n",
    "# rmse_df['Epochs'] = epochs\n",
    "\n",
    "# # Plot RMSE values\n",
    "# plt.plot(rmse_df['RMSE'], label='RMSE')\n",
    "# plt.legend()\n",
    "\n",
    "# # Find the best model_name\n",
    "# rmse_df[rmse_df['RMSE'] == rmse_df['RMSE'].min()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
